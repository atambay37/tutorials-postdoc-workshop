{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c560a25",
   "metadata": {},
   "source": [
    "The moment that we've all been waiting for has finally arrived! The Retrieval-Augmented Text Generation (RAG) Framework is here! ðŸŽ‰\n",
    "\n",
    "Throughout this notebook we will be exploring RAG, what it is, how it works, and why it's so exciting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1041c",
   "metadata": {},
   "source": [
    "## Why RAG?\n",
    "\n",
    "Although trained on large datasets, stale data can severely limit LLMs. It faces several challenges:\n",
    "\n",
    "1. The models are trained on internet content, so they might not generate relevant output when prompted for information that is not publicly available on the internet.\n",
    "\n",
    "2. The models are trained up to a certain date, they might not generate relevant output when prompted for content and information that has happened after the training completion date of the model.\n",
    "\n",
    "3. The models are trained to be more generalized. This means that they can only produce generic outputs and might not perform as expected when prompted for specific deep-dive concepts related to a particular topic.\n",
    "\n",
    "One way to dynamically integrate relevant external information is retrieval-augmented generation (RAG), which can help improve the reliability of LLM outputs.\n",
    "\n",
    "Going back to our original question of how this can be utilized in our own work or organization on [section 1](1-domain-specific-question-answering.ipynb) of this module. RAG Framework can really be useful in the scenario where there may be a set of documents, GitHub repositories, research papers, and domain-specific knowledge bases that you might want to search through quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## RAG Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "RAG proposes a solution to this issue by supplementing the prompt sent to the LLM with information from external sources through a retrieval model via vector embeddings (more on this later), thereby providing the LLM with more relevant input to generation responses. It allows you to use pre-trained LLMs without fine-tuning them or training your own LLM on your training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "![RAG Workflow](../../images/rag-workflow.webp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "\n",
    "Image Source: [Medium Blog](https://medium.com/@henryhengluo/intro-of-retrieval-augmented-generation-rag-and-application-demos-c1d9239ababf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Multiple concepts influence RAG pipeline:\n",
    "\n",
    "1. Retrieval\n",
    "2. Augmentation\n",
    "3. Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "The retrieval phase can also be considered the data and query/prompt preparation phase, focusing on efficient information retrieval or data access. To improve your RAG pipeline, the pre-retrieval phase contains tasks such as: `(1): Indexing, (2) Query Manipulation, (3) Data Modification, (4) Search, and (5) Ranking.` In this tutorial, we primarily focus on indexing and search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "`Indexing` enables fast and accurate information retrieval that sets up the context for any LLM to improve its response to a given user prompt or query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "We will be indexing abstracts for all astrophysics papers and Astropy's documentation, a common core package for Astronomy in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Embeddings, also called \"Vector Embedding,\" help LLMs develop a semantic understanding of the textual data they are trained on. In simpler terms, these embedding models lay the groundwork for LLMs to perform tasks like sentence completion, similarity search, questions and answers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50d479",
   "metadata": {},
   "source": [
    "#### Embedding vs Fine-tuning\n",
    "\n",
    "|| Embedding | Fine-tuning|\n",
    "|---|---|---|\n",
    "|**Definition**| Use pre-trained LLM as feature extractorâ€‹ | Update parameters of pre-trained LLM during task-specific training|\n",
    "|**Process**| Input Encoding > tokenizedâ€‹ > Embedding Extraction â€‹ > Downstream Task | Initialization â€‹> Task-specific Trainingâ€‹ > Fine-tuning Layers (optional)|\n",
    "|**Advantages**| Efficient use of pre-trained knowledge, Faster inference | Adaptability to task-specific nuances, May require less labeled data than from scratchâ€‹|\n",
    "|**Considerations**| N/A |Risk of overfitting, Computational cost can be high|\n",
    "|**When to use**| Limited computational resourcesâ€‹, Limited labeled data | Significant computational resources, Large corpus of labeled data|\n",
    "|**Performance**| Performs well, especially with limited dataâ€‹ | Can achieve state-of-the-art results on a wide range of tasks|\n",
    "\n",
    "### In a nutshell\n",
    "\n",
    "- Embeddings models are typically small in size and less computationally intensiveâ€‹\n",
    "\n",
    "- Regular updates of embedding vectors are faster, cheaper, and simpler compared to fine-tuning a model.â€‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "At the lowest level, machines only understand numeric values. For LLMs to work, natural language is converted into an array of numeric values before they are fed into the models. These arrays of numeric values are called \"Vector.\"\n",
    "\n",
    "An example of a vector: [2.5, 1.0, 3.3, 7.8]\n",
    "\n",
    "The above is an example of a vector of size 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: [2.5 1.7 3.3 7.8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vector = np.array([2.5, 1.7, 3.3, 7.8])\n",
    "print(f\"Vector: {vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "We stated above that **\"texts are converted into an array of numeric values called vectors\"**.\n",
    "\n",
    "But depending on your use case, each word, sentence, paragraph, or entire document can be represented as a vector. \n",
    "\n",
    "Tokens are the smallest natural language units converted into a vector. It could be at the character level, sub-word level, word level, sentence level, paragraph level, or document level.\n",
    "\n",
    "Example: Consider the text below.\n",
    "\n",
    "`Earth is a planet of the solar system. There are 9 planets in the solar system. \n",
    "All planets revolve around the sun. Sun is a star.`\n",
    "\n",
    "\n",
    "Case 1.) **Tokenizing the entire paragraph into vector.**  \n",
    "Tokenization: The entire paragraph is a single token.   \n",
    "Vectorization: A single vector.  \n",
    "Sample Vector Representation: [3.1, 6.8, 5.4, 8.0, 7.1]\n",
    "\n",
    "Case 2.) **Tokenizing each sentence into vectors.**  \n",
    "Tokenization: One token for each sentence (total 4 tokens)  \n",
    "Vectorization: One vector for each sentence (total 4 vectors).   \n",
    "Sample Vector Representation: [[1.2, 2.3, 3.8, 7.9, 0.8], [2.5, 3.0, 8.2, 6.6, 4.1], [3.2, 6.5, 8.1, 9.3, 1.4], [1.1, 0.7, 7.2, 3.5, 8.5]]\n",
    "\n",
    "Case 3.) **Tokenizing each word in the paragraph into a vector. There are 26 words in the paragraph, ignoring punctuation. Each word gets converted into a vector.**  \n",
    "Tokenization: One token for each word in the paragraph (26 tokens)  \n",
    "Vectorization: One vector for each token (total 26 vectors).    \n",
    "Sample Vector Representation: [[2.1, 3.2, 4.1, 9.8, 7.0], [8.2, 4.2, 7.1, 3.8, 2.0].....total 26 such representations]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Tokenizers are components responsible for converting large texts into tokens (tokenization). Different types of pre-trained tokenizers are available. You can even train your own tokenizers. But for the scope of this tutorial, we will use a pre-trained one. \n",
    "\n",
    "Generally, each tokenizer follows the following steps:\n",
    "\n",
    "1. Break down the original text into tokens. These tokens could again be at the character, sub-word, word, sentence, paragraph, or document levels.\n",
    "2. Assign a unique identifier to each of the tokens created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, here is how you can split a short sentence into chunks of text\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Earth is a', 'planet in', 'the solar', 'system.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "text_splitter.split_text(text=\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "[Learn more about how to split text into tokens in LangChain here.](https://python.langchain.com/v0.2/docs/how_to/split_by_token/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Embedding Models\n",
    "\n",
    "A language model needs to understand how tokens are related to each other in the context of human language. To understand this semantic relationship, these tokens are converted into numerical vectors.\n",
    "\n",
    "Embedding Models are trained upon these tokens to develop an \"embedding space.\"\n",
    "\n",
    "- Before the training, the embedding model initializes an N-dimensional 'vector' corresponding to each 'token' with random values. (Value of N depends on the embedding model)\n",
    "  \n",
    "- During the embedding model training, the values for these vectors are updated across iterations. In this process, similar or related tokens are updated to have similarly valued vectors.\n",
    "  \n",
    "- After the training, the collection of all the 'vectors' corresponding to all the tokens is called the \"embedding space.\"\n",
    "\n",
    "- \"Embedding Space\" is an encoded representation of meanings of tokens and inter-token relationships.\n",
    "\n",
    "See [Word Embeddings Resource](https://www.nlplanet.org/course-practical-nlp/01-intro-to-nlp/11-text-as-vectors-embeddings/) for more conceptual details on embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "To understand this further, let's take a look at how it all works using a pre-trained embedding model.\n",
    "\n",
    "For the tutorial and simplicity, we are using the Langchain Hugging Face integrations, which is available in the [`langchain-huggingface`](https://pypi.org/project/langchain-huggingface/) package.\n",
    "To use an embedding model available in Hugging Face,\n",
    "we will simply use the `HuggingFaceEmbedding` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbbb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f451a4ff",
   "metadata": {},
   "source": [
    "We are using the [all-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2) sentence-transformers embedding model for this tutorial.\n",
    "After [some evaluation](https://github.com/uw-ssec/tutorials/issues/6) that we did, we found that this model works well for our use case as it is lightweight and provides good performance.\n",
    "\n",
    "This model \"maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search\".\n",
    "\n",
    "However, you can use any other embedding model available in Hugging Face, and we recommend going to [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) to find embedding models and see how they compare to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshultambay/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Setup the embedding, we are using the MiniLM model here\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L12-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings_model.embed_query(\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of vector\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05409969016909599, 0.07589353621006012, -0.0419524647295475]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "In an embedding space, you can find how similar two vectors are using `dot product` or  using `cosine similarity.`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d5b4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.7926038700167977\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Similarity:\",\n",
    "    1\n",
    "    - spatial.distance.cosine(\n",
    "        query_result,\n",
    "        embeddings_model.embed_query(\"Mars is a planet in the solar system.\"),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.08770953247846214\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Similarity:\",\n",
    "    1\n",
    "    - spatial.distance.cosine(\n",
    "        query_result, embeddings_model.embed_query(\"Hello Tacoma.\")\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1513a64",
   "metadata": {},
   "source": [
    "What we have demonstrated above in finding similarity between vectors is essentially what's happening in the retrieval phase of the RAG pipeline within a *Vector Database*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### Vector Stores\n",
    "\n",
    "Once the embeddings are created for our relevant documents or knowledge base, we need to store these embeddings in the database for fast retrieval. \n",
    "\n",
    "The type of databases that store these vector embeddings are called \"Vector Stores.\" We will use a vector store called \"Qdrant,\" as shown below. \n",
    "\n",
    "In the below code, \n",
    "- Vector store works along with the embedding model to create vector embeddings.\n",
    "- Vector embeddings are stored in the Qdrant Vector database collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "We have already created a vector database that contains the astrophysics paper abstracts and Astropy's documentation, please refer to the [notebook](../appendix/astrophysics-dataset-creation.ipynb) in the Appendix.\n",
    "\n",
    "The `ssec_tutorials` utility package contains a `download_qdrant_data` function that downloads the existing Qdrant database that we've created for this tutorial.\n",
    "Additionally, there's a `QDRANT_COLLECTION_NAME` constant variable\n",
    "that contains the name of the collection in the Qdrant database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de21b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssec_tutorials import download_qdrant_data, QDRANT_COLLECTION_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant data already exists at /Users/anshultambay/.cache/ssec_tutorials/scipy_qdrant\n"
     ]
    }
   ],
   "source": [
    "QDRANT_PATH = download_qdrant_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bacdd0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/anshultambay/.cache/ssec_tutorials/scipy_qdrant')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv_astro-ph_abstracts_astropy_github_documentation'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_COLLECTION_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc7155",
   "metadata": {},
   "source": [
    "With having the Qdrant path and collection name information, as well as the embeddings model, we can now use the Langchain Qdrant integrations package called `langchain-qdrant` to interact with the Qdrant database by using the `Qdrant` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a3744c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eae38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant = Qdrant.from_existing_collection(\n",
    "    embedding=embeddings_model,\n",
    "    collection_name=QDRANT_COLLECTION_NAME,\n",
    "    path=QDRANT_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73d977",
   "metadata": {},
   "source": [
    "Now that we have the Qdrant database instance, we are ready to search for the relevant documents based on the user query.\n",
    "However, before we can simply search, we will need a [`VectorStoreRetriever`](https://python.langchain.com/v0.2/docs/how_to/vectorstore_retriever/) object.\n",
    "\n",
    "To get the `VectorStoreRetriever` object, we can simply call the `.as_retriever()` method on the Qdrant object.\n",
    "\n",
    "In this example, we will be setting the `search_type` to `\"mmr\"` and `search_kwargs` to `{\"k\": 2}`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7aa006",
   "metadata": {},
   "source": [
    "\"mmr\" stands for  Maximum Marginal Relevance\n",
    "\n",
    "MMR selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.\n",
    "\n",
    "The `k` parameter in `search_kwargs` specifies the number of documents to retrieve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the retriever for later step\n",
    "retriever = qdrant.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf703bba",
   "metadata": {},
   "source": [
    "Let's invoke this retriever object with some of the questions from previous section and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = retriever.invoke(\"What is the best method for multiplying large numbers?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9512a",
   "metadata": {},
   "source": [
    "We got the relevant documents from the Qdrant database for the given questions. Let's see what these documents look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04949b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e641df5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac457806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_content': '.. _nddata_arithmetic:\\n\\nNDData Arithmetic\\n*****************\\n\\nIntroduction\\n============\\n\\n`~astropy.nddata.NDDataRef` implements the following arithmetic operations:\\n\\n- Addition: :meth:`~astropy.nddata.NDArithmeticMixin.add`\\n- Subtraction: :meth:`~astropy.nddata.NDArithmeticMixin.subtract`\\n- Multiplication: :meth:`~astropy.nddata.NDArithmeticMixin.multiply`\\n- Division: :meth:`~astropy.nddata.NDArithmeticMixin.divide`\\n\\nUsing Basic Arithmetic Methods\\n==============================\\n\\nUsing the standard arithmetic methods requires that the first operand\\nis an `~astropy.nddata.NDDataRef` instance:\\n\\n    >>> from astropy.nddata import NDDataRef\\n    >>> from astropy.wcs import WCS\\n    >>> import numpy as np\\n    >>> ndd1 = NDDataRef([1, 2, 3, 4])\\n\\nWhile the requirement for the second operand is that it must be convertible\\nto the first operand. It can be a number::\\n\\n    >>> ndd1.add(3)\\n    NDDataRef([4, 5, 6, 7])\\n\\nOr a `list`::\\n\\n    >>> ndd1.subtract([1,1,1,1])\\n    NDDataRef([0, 1, 2, 3])\\n\\nOr a `numpy.ndarray`::\\n\\n    >>> ndd1.multiply(np.arange(4, 8))\\n    NDDataRef([ 4, 10, 18, 28])\\n    >>> ndd1.divide(np.arange(1,13).reshape(3,4))  # a 3 x 4 numpy array  # doctest: +FLOAT_CMP\\n    NDDataRef([[1.        , 1.        , 1.        , 1.        ],\\n               [0.2       , 0.33333333, 0.42857143, 0.5       ],\\n               [0.11111111, 0.2       , 0.27272727, 0.33333333]])\\n\\nHere, broadcasting takes care of the different dimensions. Several other\\ntypes of operands are also accepted.\\n\\nUsing Arithmetic Classmethods\\n=============================\\n\\nHere both operands do not need to be `~astropy.nddata.NDDataRef`-like::\\n\\n    >>> NDDataRef.add(1, 3)\\n    NDDataRef(4)\\n\\nTo wrap the result of an arithmetic operation between two Quantities::\\n\\n    >>> import astropy.units as u\\n    >>> ndd = NDDataRef.multiply([1,2] * u.m, [10, 20] * u.cm)\\n    >>> ndd  # doctest: +FLOAT_CMP\\n    NDDataRef([10., 40.], unit=\\'cm m\\')\\n    >>> ndd.unit\\n    Unit(\"cm m\")\\n\\nOr take the inverse of an `~astropy.nddata.NDDataRef` object::\\n\\n    >>> NDDataRef.divide(1, ndd1)  # doctest: +FLOAT_CMP\\n    NDDataRef([1.        , 0.5       , 0.33333333, 0.25      ])\\n\\n\\nPossible Operands\\n-----------------\\n\\nThe possible types of input for operands are:\\n\\n+ Scalars of any type\\n+ Lists containing numbers (or nested lists)\\n+ ``numpy`` arrays\\n+ ``numpy`` masked arrays\\n+ ``astropy`` quantities\\n+ Other ``nddata`` classes or subclasses\\n\\nAdvanced Options\\n================\\n\\nThe normal Python operators ``+``, ``-``, etc. are not implemented because\\nthe methods provide several options on how to proceed with the additional\\nattributes.\\n\\nData and Unit\\n-------------\\n\\nFor ``data`` and ``unit`` there are no parameters. Every arithmetic\\noperation lets the `astropy.units.Quantity`-framework evaluate the result\\nor fail and abort the operation.\\n\\nAdding two `~astropy.nddata.NDData` objects with the same unit works::\\n\\n    >>> ndd1 = NDDataRef([1,2,3,4,5], unit=\\'m\\')\\n    >>> ndd2 = NDDataRef([100,150,200,50,500], unit=\\'m\\')\\n\\n    >>> ndd = ndd1.add(ndd2)\\n    >>> ndd.data  # doctest: +FLOAT_CMP\\n    array([101., 152., 203., 54., 505.])\\n    >>> ndd.unit\\n    Unit(\"m\")\\n\\nAdding two `~astropy.nddata.NDData` objects with compatible units also works::\\n\\n    >>> ndd1 = NDDataRef(ndd1, unit=\\'pc\\')\\n    INFO: overwriting NDData\\'s current unit with specified unit. [astropy.nddata.nddata]\\n    >>> ndd2 = NDDataRef(ndd2, unit=\\'lyr\\')\\n    INFO: overwriting NDData\\'s current unit with specified unit. [astropy.nddata.nddata]\\n\\n    >>> ndd = ndd1.subtract(ndd2)\\n    >>> ndd.data  # doctest: +FLOAT_CMP\\n    array([ -29.66013938,  -43.99020907,  -58.32027876,  -11.33006969,\\n           -148.30069689])\\n    >>> ndd.unit\\n    Unit(\"pc\")\\n\\nThis will keep by default the unit of the first operand. However, units will\\nnot be decomposed during division::\\n\\n    >>> ndd = ndd2.divide(ndd1)\\n    >>> ndd.data  # doctest: +FLOAT_CMP\\n    array([100. , 75. , 66.66666667, 12.5 , 100. ])\\n    >>> ndd.unit\\n    Unit(\"lyr / pc\")\\n\\nMask\\n----\\n\\nThe ``handle_mask`` parameter for the arithmetic operations implements what the\\nresulting mask will be. There are several options.\\n\\n- ``None``, the result will have no ``mask``::\\n\\n      >>> ndd1 = NDDataRef(1, mask=True)\\n      >>> ndd2 = NDDataRef(1, mask=False)\\n      >>> ndd1.add(ndd2, handle_mask=None).mask is None\\n      True\\n\\n- ``\"first_found\"`` or ``\"ff\"``, the result will have the ``mask`` of the first\\n  operand or if that is ``None``, the ``mask`` of the second operand::\\n\\n      >>> ndd1 = NDDataRef(1, mask=True)\\n      >>> ndd2 = NDDataRef(1, mask=False)\\n      >>> ndd1.add(ndd2, handle_mask=\"first_found\").mask\\n      True\\n      >>> ndd3 = NDDataRef(1)\\n      >>> ndd3.add(ndd2, handle_mask=\"first_found\").mask\\n      False\\n\\n- A function (or an arbitrary callable) that takes at least two arguments.\\n  For example, `numpy.logical_or` is the default::\\n\\n      >>> ndd1 = NDDataRef(1, mask=np.array([True, False, True, False]))\\n      >>> ndd2 = NDDataRef(1, mask=np.array([True, False, False, True]))\\n      >>> ndd1.add(ndd2).mask\\n      array([ True, False,  True,  True]...)\\n\\n  This defaults to ``\"first_found\"`` in case only one ``mask`` is not None::\\n\\n      >>> ndd1 = NDDataRef(1)\\n      >>> ndd2 = NDDataRef(1, mask=np.array([True, False, False, True]))\\n      >>> ndd1.add(ndd2).mask\\n      array([ True, False, False,  True]...)\\n\\n  Custom functions are also possible::\\n\\n      >>> def take_alternating_values(mask1, mask2, start=0):\\n      ...     result = np.zeros(mask1.shape, dtype=np.bool_)\\n      ...     result[start::2] = mask1[start::2]\\n      ...     result[start+1::2] = mask2[start+1::2]\\n      ...     return result\\n\\n  This function is nonsense, but we can still see how it performs::\\n\\n      >>> ndd1 = NDDataRef(1, mask=np.array([True, False, True, False]))\\n      >>> ndd2 = NDDataRef(1, mask=np.array([True, False, False, True]))\\n      >>> ndd1.add(ndd2, handle_mask=take_alternating_values).mask\\n      array([ True, False,  True,  True]...)\\n\\n  Additional parameters can be given by prefixing them with ``mask_``\\n  (which will be stripped before passing it to the function)::\\n\\n      >>> ndd1.add(ndd2, handle_mask=take_alternating_values, mask_start=1).mask\\n      array([False, False, False, False]...)\\n      >>> ndd1.add(ndd2, handle_mask=take_alternating_values, mask_start=2).mask\\n      array([False, False,  True,  True]...)\\n\\nMeta\\n----\\n\\nThe ``handle_meta`` parameter for the arithmetic operations implements what the\\nresulting ``meta`` will be. The options are the same as for the ``mask``:\\n\\n- If ``None`` the resulting ``meta`` will be an empty `collections.OrderedDict`.\\n\\n      >>> ndd1 = NDDataRef(1, meta={\\'object\\': \\'sun\\'})\\n      >>> ndd2 = NDDataRef(1, meta={\\'object\\': \\'moon\\'})\\n      >>> ndd1.add(ndd2, handle_meta=None).meta\\n      OrderedDict()\\n\\n  For ``meta`` this is the default so you do not need to pass it in this case::\\n\\n      >>> ndd1.add(ndd2).meta\\n      OrderedDict()\\n\\n- If ``\"first_found\"`` or ``\"ff\"``, the resulting ``meta`` will be the ``meta``\\n  of the first operand or if that contains no keys, the ``meta`` of the second\\n  operand is taken.\\n\\n      >>> ndd1 = NDDataRef(1, meta={\\'object\\': \\'sun\\'})\\n      >>> ndd2 = NDDataRef(1, meta={\\'object\\': \\'moon\\'})\\n      >>> ndd1.add(ndd2, handle_meta=\\'ff\\').meta\\n      {\\'object\\': \\'sun\\'}\\n\\n- If it is a ``callable`` it must take at least two arguments. Both ``meta``\\n  attributes will be passed to this function (even if one or both of them are\\n  empty) and the callable evaluates the result\\'s ``meta``. For example, a\\n  function that merges these two::\\n\\n      >>> # It\\'s expected with arithmetic that the result is not a reference,\\n      >>> # so we need to copy\\n      >>> from copy import deepcopy\\n\\n      >>> def combine_meta(meta1, meta2):\\n      ...     if not meta1:\\n      ...         return deepcopy(meta2)\\n      ...     elif not meta2:\\n      ...         return deepcopy(meta1)\\n      ...     else:\\n      ...         meta_final = deepcopy(meta1)\\n      ...         meta_final.update(meta2)\\n      ...         return meta_final\\n\\n      >>> ndd1 = NDDataRef(1, meta={\\'time\\': \\'today\\'})\\n      >>> ndd2 = NDDataRef(1, meta={\\'object\\': \\'moon\\'})\\n      >>> ndd1.subtract(ndd2, handle_meta=combine_meta).meta # doctest: +SKIP\\n      {\\'object\\': \\'moon\\', \\'time\\': \\'today\\'}\\n\\n  Here again additional arguments for the function can be passed in using\\n  the prefix ``meta_`` (which will be stripped away before passing it to this\\n  function). See the description for the mask-attribute for further details.\\n\\nWorld Coordinate System (WCS)\\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\nThe ``compare_wcs`` argument will determine what the result\\'s ``wcs`` will be\\nor if the operation should be forbidden. The possible values are identical to\\n``mask`` and ``meta``:\\n\\n- If ``None`` the resulting ``wcs`` will be an empty ``None``.\\n\\n      >>> ndd1 = NDDataRef(1, wcs=None)\\n      >>> ndd2 = NDDataRef(1, wcs=WCS())\\n      >>> ndd1.add(ndd2, compare_wcs=None).wcs is None\\n      True\\n\\n- If ``\"first_found\"`` or ``\"ff\"`` the resulting ``wcs`` will be the ``wcs`` of\\n  the first operand or if that is ``None``, the ``meta`` of the second operand\\n  is taken.\\n\\n      >>> wcs = WCS()\\n      >>> ndd1 = NDDataRef(1, wcs=wcs)\\n      >>> ndd2 = NDDataRef(1, wcs=None)\\n      >>> str(ndd1.add(ndd2, compare_wcs=\\'ff\\').wcs) == str(wcs)\\n      True\\n\\n- If it is a ``callable`` it must take at least two arguments. Both ``wcs``\\n  attributes will be passed to this function (even if one or both of them are\\n  ``None``) and the callable should return ``True`` if these ``wcs`` are\\n  identical (enough) to allow the arithmetic operation or ``False`` if the\\n  arithmetic operation should be aborted with a ``ValueError``. If ``True`` the\\n  ``wcs`` are identical and the first one is used for the result::\\n\\n      >>> def compare_wcs_scalar(wcs1, wcs2, allowed_deviation=0.1):\\n      ...     if wcs1 is None and wcs2 is None:\\n      ...         return True  # both have no WCS so they are identical\\n      ...     if wcs1 is None or wcs2 is None:\\n      ...         return False  # one has WCS, the other doesn\\'t not possible\\n      ...     else:\\n      ...         # Consider wcs close if centers are close enough\\n      ...         return all(abs(wcs1.wcs.crpix - wcs2.wcs.crpix) < allowed_deviation)\\n\\n      >>> ndd1 = NDDataRef(1, wcs=None)\\n      >>> ndd2 = NDDataRef(1, wcs=None)\\n      >>> ndd1.subtract(ndd2, compare_wcs=compare_wcs_scalar).wcs\\n\\n\\n  Additional arguments can be passed in prefixing them with ``wcs_`` (this\\n  prefix will be stripped away before passing it to the function)::\\n\\n      >>> ndd1 = NDDataRef(1, wcs=WCS())\\n      >>> ndd1.wcs.wcs.crpix = [1, 1]\\n      >>> ndd2 = NDDataRef(1, wcs=WCS())\\n      >>> ndd1.subtract(ndd2, compare_wcs=compare_wcs_scalar, wcs_allowed_deviation=2).wcs.wcs.crpix\\n      array([1., 1.])\\n\\n  If you are using `~astropy.wcs.WCS` objects, a very handy function to use\\n  might be::\\n\\n      >>> def wcs_compare(wcs1, wcs2, *args, **kwargs):\\n      ...     return wcs1.wcs.compare(wcs2.wcs, *args, **kwargs)\\n\\n  See :meth:`astropy.wcs.Wcsprm.compare` for the arguments this comparison\\n  allows.\\n\\nUncertainty\\n-----------\\n\\nThe ``propagate_uncertainties`` argument can be used to turn the propagation\\nof uncertainties on or off.\\n\\n- If ``None`` the result will have no uncertainty::\\n\\n      >>> from astropy.nddata import StdDevUncertainty\\n      >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty(0))\\n      >>> ndd2 = NDDataRef(1, uncertainty=StdDevUncertainty(1))\\n      >>> ndd1.add(ndd2, propagate_uncertainties=None).uncertainty is None\\n      True\\n\\n- If ``False`` the result will have the first found uncertainty.\\n\\n  .. note::\\n      Setting ``propagate_uncertainties=False`` is generally not\\n      recommended.\\n\\n- If ``True`` both uncertainties must be ``NDUncertainty`` subclasses that\\n  implement propagation. This is possible for\\n  `~astropy.nddata.StdDevUncertainty`::\\n\\n      >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\\n      >>> ndd2 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\\n      >>> ndd1.add(ndd2, propagate_uncertainties=True).uncertainty  # doctest: +FLOAT_CMP\\n      StdDevUncertainty([14.14213562])\\n\\nUncertainty with Correlation\\n----------------------------\\n\\nIf ``propagate_uncertainties`` is ``True`` you can also give an argument\\nfor ``uncertainty_correlation``. `~astropy.nddata.StdDevUncertainty` cannot\\nkeep track of its correlations by itself, but it can evaluate the correct\\nresulting uncertainty if the correct ``correlation`` is given.\\n\\nThe default (``0``) represents uncorrelated while ``1`` means correlated and\\n``-1`` anti-correlated. If given a `numpy.ndarray` it should represent the\\nelement-wise correlation coefficient.\\n\\nExamples\\n^^^^^^^^\\n\\n..\\n  EXAMPLE START\\n  Uncertainty with Correlation in NDData\\n\\nWithout correlation, subtracting an `~astropy.nddata.NDDataRef` instance from\\nitself results in a non-zero uncertainty::\\n\\n    >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\\n    >>> ndd1.subtract(ndd1, propagate_uncertainties=True).uncertainty  # doctest: +FLOAT_CMP\\n    StdDevUncertainty([14.14213562])\\n\\nGiven a correlation of ``1`` (because they clearly correlate) gives the\\ncorrect uncertainty of ``0``::\\n\\n    >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\\n    >>> ndd1.subtract(ndd1, propagate_uncertainties=True,\\n    ...               uncertainty_correlation=1).uncertainty  # doctest: +FLOAT_CMP\\n    StdDevUncertainty([0.])\\n\\nWhich would be consistent with the equivalent operation ``ndd1 * 0``::\\n\\n    >>> ndd1.multiply(0, propagate_uncertainties=True).uncertainty # doctest: +FLOAT_CMP\\n    StdDevUncertainty([0.])\\n\\n.. warning::\\n    The user needs to calculate or know the appropriate value or array manually\\n    and pass it to ``uncertainty_correlation``. The implementation follows\\n    general first order error propagation formulas. See, for example:\\n    `Wikipedia <https://en.wikipedia.org/wiki/Propagation_of_uncertainty#Example_formulas>`_.\\n\\nYou can also give element-wise correlations::\\n\\n    >>> ndd1 = NDDataRef([1,1,1,1], uncertainty=StdDevUncertainty([1,1,1,1]))\\n    >>> ndd2 = NDDataRef([2,2,2,2], uncertainty=StdDevUncertainty([2,2,2,2]))\\n    >>> ndd1.add(ndd2,uncertainty_correlation=np.array([1,0.5,0,-1])).uncertainty  # doctest: +FLOAT_CMP\\n    StdDevUncertainty([3.        , 2.64575131, 2.23606798, 1.        ])\\n\\nThe correlation ``np.array([1, 0.5, 0, -1])`` would indicate that the first\\nelement is fully correlated and the second element partially correlates, while\\nthe third element is uncorrelated, and the fourth is anti-correlated.\\n\\n..\\n  EXAMPLE END\\n\\nUncertainty with Unit\\n---------------------\\n\\n`~astropy.nddata.StdDevUncertainty` implements correct error propagation even\\nif the unit of the data differs from the unit of the uncertainty::\\n\\n    >>> ndd1 = NDDataRef([10], unit=\\'m\\', uncertainty=StdDevUncertainty([10], unit=\\'cm\\'))\\n    >>> ndd2 = NDDataRef([20], unit=\\'m\\', uncertainty=StdDevUncertainty([10]))\\n    >>> ndd1.subtract(ndd2, propagate_uncertainties=True).uncertainty  # doctest: +FLOAT_CMP\\n    StdDevUncertainty([10.00049999])\\n\\nBut it needs to be convertible to the unit for the data.\\n',\n",
       " 'metadata': {'title': 'Ndarithmetic',\n",
       "  'url': 'https://raw.githubusercontent.com/astropy/astropy/main/docs/nddata/mixins/ndarithmetic.rst',\n",
       "  '_id': '183960d10d1845198f9d1abb65fb96de',\n",
       "  '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'},\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d66587e",
   "metadata": {},
   "source": [
    "We see that this is a core Langchain Document object that contains the document's metadata and content.\n",
    "\n",
    "Later we will see how we can use this document to generate the response, for now let's create a utility formatting function to retrieve just the content of the document so that we can put this as part of our prompt template input, also known as \"Augmentation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _nddata_arithmetic:\n",
      "\n",
      "NDData Arithmetic\n",
      "*****************\n",
      "\n",
      "Introduction\n",
      "============\n",
      "\n",
      "`~astropy.nddata.NDDataRef` implements the following arithmetic operations:\n",
      "\n",
      "- Addition: :meth:`~astropy.nddata.NDArithmeticMixin.add`\n",
      "- Subtraction: :meth:`~astropy.nddata.NDArithmeticMixin.subtract`\n",
      "- Multiplication: :meth:`~astropy.nddata.NDArithmeticMixin.multiply`\n",
      "- Division: :meth:`~astropy.nddata.NDArithmeticMixin.divide`\n",
      "\n",
      "Using Basic Arithmetic Methods\n",
      "==============================\n",
      "\n",
      "Using the standard arithmetic methods requires that the first operand\n",
      "is an `~astropy.nddata.NDDataRef` instance:\n",
      "\n",
      "    >>> from astropy.nddata import NDDataRef\n",
      "    >>> from astropy.wcs import WCS\n",
      "    >>> import numpy as np\n",
      "    >>> ndd1 = NDDataRef([1, 2, 3, 4])\n",
      "\n",
      "While the requirement for the second operand is that it must be convertible\n",
      "to the first operand. It can be a number::\n",
      "\n",
      "    >>> ndd1.add(3)\n",
      "    NDDataRef([4, 5, 6, 7])\n",
      "\n",
      "Or a `list`::\n",
      "\n",
      "    >>> ndd1.subtract([1,1,1,1])\n",
      "    NDDataRef([0, 1, 2, 3])\n",
      "\n",
      "Or a `numpy.ndarray`::\n",
      "\n",
      "    >>> ndd1.multiply(np.arange(4, 8))\n",
      "    NDDataRef([ 4, 10, 18, 28])\n",
      "    >>> ndd1.divide(np.arange(1,13).reshape(3,4))  # a 3 x 4 numpy array  # doctest: +FLOAT_CMP\n",
      "    NDDataRef([[1.        , 1.        , 1.        , 1.        ],\n",
      "               [0.2       , 0.33333333, 0.42857143, 0.5       ],\n",
      "               [0.11111111, 0.2       , 0.27272727, 0.33333333]])\n",
      "\n",
      "Here, broadcasting takes care of the different dimensions. Several other\n",
      "types of operands are also accepted.\n",
      "\n",
      "Using Arithmetic Classmethods\n",
      "=============================\n",
      "\n",
      "Here both operands do not need to be `~astropy.nddata.NDDataRef`-like::\n",
      "\n",
      "    >>> NDDataRef.add(1, 3)\n",
      "    NDDataRef(4)\n",
      "\n",
      "To wrap the result of an arithmetic operation between two Quantities::\n",
      "\n",
      "    >>> import astropy.units as u\n",
      "    >>> ndd = NDDataRef.multiply([1,2] * u.m, [10, 20] * u.cm)\n",
      "    >>> ndd  # doctest: +FLOAT_CMP\n",
      "    NDDataRef([10., 40.], unit='cm m')\n",
      "    >>> ndd.unit\n",
      "    Unit(\"cm m\")\n",
      "\n",
      "Or take the inverse of an `~astropy.nddata.NDDataRef` object::\n",
      "\n",
      "    >>> NDDataRef.divide(1, ndd1)  # doctest: +FLOAT_CMP\n",
      "    NDDataRef([1.        , 0.5       , 0.33333333, 0.25      ])\n",
      "\n",
      "\n",
      "Possible Operands\n",
      "-----------------\n",
      "\n",
      "The possible types of input for operands are:\n",
      "\n",
      "+ Scalars of any type\n",
      "+ Lists containing numbers (or nested lists)\n",
      "+ ``numpy`` arrays\n",
      "+ ``numpy`` masked arrays\n",
      "+ ``astropy`` quantities\n",
      "+ Other ``nddata`` classes or subclasses\n",
      "\n",
      "Advanced Options\n",
      "================\n",
      "\n",
      "The normal Python operators ``+``, ``-``, etc. are not implemented because\n",
      "the methods provide several options on how to proceed with the additional\n",
      "attributes.\n",
      "\n",
      "Data and Unit\n",
      "-------------\n",
      "\n",
      "For ``data`` and ``unit`` there are no parameters. Every arithmetic\n",
      "operation lets the `astropy.units.Quantity`-framework evaluate the result\n",
      "or fail and abort the operation.\n",
      "\n",
      "Adding two `~astropy.nddata.NDData` objects with the same unit works::\n",
      "\n",
      "    >>> ndd1 = NDDataRef([1,2,3,4,5], unit='m')\n",
      "    >>> ndd2 = NDDataRef([100,150,200,50,500], unit='m')\n",
      "\n",
      "    >>> ndd = ndd1.add(ndd2)\n",
      "    >>> ndd.data  # doctest: +FLOAT_CMP\n",
      "    array([101., 152., 203., 54., 505.])\n",
      "    >>> ndd.unit\n",
      "    Unit(\"m\")\n",
      "\n",
      "Adding two `~astropy.nddata.NDData` objects with compatible units also works::\n",
      "\n",
      "    >>> ndd1 = NDDataRef(ndd1, unit='pc')\n",
      "    INFO: overwriting NDData's current unit with specified unit. [astropy.nddata.nddata]\n",
      "    >>> ndd2 = NDDataRef(ndd2, unit='lyr')\n",
      "    INFO: overwriting NDData's current unit with specified unit. [astropy.nddata.nddata]\n",
      "\n",
      "    >>> ndd = ndd1.subtract(ndd2)\n",
      "    >>> ndd.data  # doctest: +FLOAT_CMP\n",
      "    array([ -29.66013938,  -43.99020907,  -58.32027876,  -11.33006969,\n",
      "           -148.30069689])\n",
      "    >>> ndd.unit\n",
      "    Unit(\"pc\")\n",
      "\n",
      "This will keep by default the unit of the first operand. However, units will\n",
      "not be decomposed during division::\n",
      "\n",
      "    >>> ndd = ndd2.divide(ndd1)\n",
      "    >>> ndd.data  # doctest: +FLOAT_CMP\n",
      "    array([100. , 75. , 66.66666667, 12.5 , 100. ])\n",
      "    >>> ndd.unit\n",
      "    Unit(\"lyr / pc\")\n",
      "\n",
      "Mask\n",
      "----\n",
      "\n",
      "The ``handle_mask`` parameter for the arithmetic operations implements what the\n",
      "resulting mask will be. There are several options.\n",
      "\n",
      "- ``None``, the result will have no ``mask``::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, mask=True)\n",
      "      >>> ndd2 = NDDataRef(1, mask=False)\n",
      "      >>> ndd1.add(ndd2, handle_mask=None).mask is None\n",
      "      True\n",
      "\n",
      "- ``\"first_found\"`` or ``\"ff\"``, the result will have the ``mask`` of the first\n",
      "  operand or if that is ``None``, the ``mask`` of the second operand::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, mask=True)\n",
      "      >>> ndd2 = NDDataRef(1, mask=False)\n",
      "      >>> ndd1.add(ndd2, handle_mask=\"first_found\").mask\n",
      "      True\n",
      "      >>> ndd3 = NDDataRef(1)\n",
      "      >>> ndd3.add(ndd2, handle_mask=\"first_found\").mask\n",
      "      False\n",
      "\n",
      "- A function (or an arbitrary callable) that takes at least two arguments.\n",
      "  For example, `numpy.logical_or` is the default::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, mask=np.array([True, False, True, False]))\n",
      "      >>> ndd2 = NDDataRef(1, mask=np.array([True, False, False, True]))\n",
      "      >>> ndd1.add(ndd2).mask\n",
      "      array([ True, False,  True,  True]...)\n",
      "\n",
      "  This defaults to ``\"first_found\"`` in case only one ``mask`` is not None::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1)\n",
      "      >>> ndd2 = NDDataRef(1, mask=np.array([True, False, False, True]))\n",
      "      >>> ndd1.add(ndd2).mask\n",
      "      array([ True, False, False,  True]...)\n",
      "\n",
      "  Custom functions are also possible::\n",
      "\n",
      "      >>> def take_alternating_values(mask1, mask2, start=0):\n",
      "      ...     result = np.zeros(mask1.shape, dtype=np.bool_)\n",
      "      ...     result[start::2] = mask1[start::2]\n",
      "      ...     result[start+1::2] = mask2[start+1::2]\n",
      "      ...     return result\n",
      "\n",
      "  This function is nonsense, but we can still see how it performs::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, mask=np.array([True, False, True, False]))\n",
      "      >>> ndd2 = NDDataRef(1, mask=np.array([True, False, False, True]))\n",
      "      >>> ndd1.add(ndd2, handle_mask=take_alternating_values).mask\n",
      "      array([ True, False,  True,  True]...)\n",
      "\n",
      "  Additional parameters can be given by prefixing them with ``mask_``\n",
      "  (which will be stripped before passing it to the function)::\n",
      "\n",
      "      >>> ndd1.add(ndd2, handle_mask=take_alternating_values, mask_start=1).mask\n",
      "      array([False, False, False, False]...)\n",
      "      >>> ndd1.add(ndd2, handle_mask=take_alternating_values, mask_start=2).mask\n",
      "      array([False, False,  True,  True]...)\n",
      "\n",
      "Meta\n",
      "----\n",
      "\n",
      "The ``handle_meta`` parameter for the arithmetic operations implements what the\n",
      "resulting ``meta`` will be. The options are the same as for the ``mask``:\n",
      "\n",
      "- If ``None`` the resulting ``meta`` will be an empty `collections.OrderedDict`.\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, meta={'object': 'sun'})\n",
      "      >>> ndd2 = NDDataRef(1, meta={'object': 'moon'})\n",
      "      >>> ndd1.add(ndd2, handle_meta=None).meta\n",
      "      OrderedDict()\n",
      "\n",
      "  For ``meta`` this is the default so you do not need to pass it in this case::\n",
      "\n",
      "      >>> ndd1.add(ndd2).meta\n",
      "      OrderedDict()\n",
      "\n",
      "- If ``\"first_found\"`` or ``\"ff\"``, the resulting ``meta`` will be the ``meta``\n",
      "  of the first operand or if that contains no keys, the ``meta`` of the second\n",
      "  operand is taken.\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, meta={'object': 'sun'})\n",
      "      >>> ndd2 = NDDataRef(1, meta={'object': 'moon'})\n",
      "      >>> ndd1.add(ndd2, handle_meta='ff').meta\n",
      "      {'object': 'sun'}\n",
      "\n",
      "- If it is a ``callable`` it must take at least two arguments. Both ``meta``\n",
      "  attributes will be passed to this function (even if one or both of them are\n",
      "  empty) and the callable evaluates the result's ``meta``. For example, a\n",
      "  function that merges these two::\n",
      "\n",
      "      >>> # It's expected with arithmetic that the result is not a reference,\n",
      "      >>> # so we need to copy\n",
      "      >>> from copy import deepcopy\n",
      "\n",
      "      >>> def combine_meta(meta1, meta2):\n",
      "      ...     if not meta1:\n",
      "      ...         return deepcopy(meta2)\n",
      "      ...     elif not meta2:\n",
      "      ...         return deepcopy(meta1)\n",
      "      ...     else:\n",
      "      ...         meta_final = deepcopy(meta1)\n",
      "      ...         meta_final.update(meta2)\n",
      "      ...         return meta_final\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, meta={'time': 'today'})\n",
      "      >>> ndd2 = NDDataRef(1, meta={'object': 'moon'})\n",
      "      >>> ndd1.subtract(ndd2, handle_meta=combine_meta).meta # doctest: +SKIP\n",
      "      {'object': 'moon', 'time': 'today'}\n",
      "\n",
      "  Here again additional arguments for the function can be passed in using\n",
      "  the prefix ``meta_`` (which will be stripped away before passing it to this\n",
      "  function). See the description for the mask-attribute for further details.\n",
      "\n",
      "World Coordinate System (WCS)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "The ``compare_wcs`` argument will determine what the result's ``wcs`` will be\n",
      "or if the operation should be forbidden. The possible values are identical to\n",
      "``mask`` and ``meta``:\n",
      "\n",
      "- If ``None`` the resulting ``wcs`` will be an empty ``None``.\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, wcs=None)\n",
      "      >>> ndd2 = NDDataRef(1, wcs=WCS())\n",
      "      >>> ndd1.add(ndd2, compare_wcs=None).wcs is None\n",
      "      True\n",
      "\n",
      "- If ``\"first_found\"`` or ``\"ff\"`` the resulting ``wcs`` will be the ``wcs`` of\n",
      "  the first operand or if that is ``None``, the ``meta`` of the second operand\n",
      "  is taken.\n",
      "\n",
      "      >>> wcs = WCS()\n",
      "      >>> ndd1 = NDDataRef(1, wcs=wcs)\n",
      "      >>> ndd2 = NDDataRef(1, wcs=None)\n",
      "      >>> str(ndd1.add(ndd2, compare_wcs='ff').wcs) == str(wcs)\n",
      "      True\n",
      "\n",
      "- If it is a ``callable`` it must take at least two arguments. Both ``wcs``\n",
      "  attributes will be passed to this function (even if one or both of them are\n",
      "  ``None``) and the callable should return ``True`` if these ``wcs`` are\n",
      "  identical (enough) to allow the arithmetic operation or ``False`` if the\n",
      "  arithmetic operation should be aborted with a ``ValueError``. If ``True`` the\n",
      "  ``wcs`` are identical and the first one is used for the result::\n",
      "\n",
      "      >>> def compare_wcs_scalar(wcs1, wcs2, allowed_deviation=0.1):\n",
      "      ...     if wcs1 is None and wcs2 is None:\n",
      "      ...         return True  # both have no WCS so they are identical\n",
      "      ...     if wcs1 is None or wcs2 is None:\n",
      "      ...         return False  # one has WCS, the other doesn't not possible\n",
      "      ...     else:\n",
      "      ...         # Consider wcs close if centers are close enough\n",
      "      ...         return all(abs(wcs1.wcs.crpix - wcs2.wcs.crpix) < allowed_deviation)\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, wcs=None)\n",
      "      >>> ndd2 = NDDataRef(1, wcs=None)\n",
      "      >>> ndd1.subtract(ndd2, compare_wcs=compare_wcs_scalar).wcs\n",
      "\n",
      "\n",
      "  Additional arguments can be passed in prefixing them with ``wcs_`` (this\n",
      "  prefix will be stripped away before passing it to the function)::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, wcs=WCS())\n",
      "      >>> ndd1.wcs.wcs.crpix = [1, 1]\n",
      "      >>> ndd2 = NDDataRef(1, wcs=WCS())\n",
      "      >>> ndd1.subtract(ndd2, compare_wcs=compare_wcs_scalar, wcs_allowed_deviation=2).wcs.wcs.crpix\n",
      "      array([1., 1.])\n",
      "\n",
      "  If you are using `~astropy.wcs.WCS` objects, a very handy function to use\n",
      "  might be::\n",
      "\n",
      "      >>> def wcs_compare(wcs1, wcs2, *args, **kwargs):\n",
      "      ...     return wcs1.wcs.compare(wcs2.wcs, *args, **kwargs)\n",
      "\n",
      "  See :meth:`astropy.wcs.Wcsprm.compare` for the arguments this comparison\n",
      "  allows.\n",
      "\n",
      "Uncertainty\n",
      "-----------\n",
      "\n",
      "The ``propagate_uncertainties`` argument can be used to turn the propagation\n",
      "of uncertainties on or off.\n",
      "\n",
      "- If ``None`` the result will have no uncertainty::\n",
      "\n",
      "      >>> from astropy.nddata import StdDevUncertainty\n",
      "      >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty(0))\n",
      "      >>> ndd2 = NDDataRef(1, uncertainty=StdDevUncertainty(1))\n",
      "      >>> ndd1.add(ndd2, propagate_uncertainties=None).uncertainty is None\n",
      "      True\n",
      "\n",
      "- If ``False`` the result will have the first found uncertainty.\n",
      "\n",
      "  .. note::\n",
      "      Setting ``propagate_uncertainties=False`` is generally not\n",
      "      recommended.\n",
      "\n",
      "- If ``True`` both uncertainties must be ``NDUncertainty`` subclasses that\n",
      "  implement propagation. This is possible for\n",
      "  `~astropy.nddata.StdDevUncertainty`::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\n",
      "      >>> ndd2 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\n",
      "      >>> ndd1.add(ndd2, propagate_uncertainties=True).uncertainty  # doctest: +FLOAT_CMP\n",
      "      StdDevUncertainty([14.14213562])\n",
      "\n",
      "Uncertainty with Correlation\n",
      "----------------------------\n",
      "\n",
      "If ``propagate_uncertainties`` is ``True`` you can also give an argument\n",
      "for ``uncertainty_correlation``. `~astropy.nddata.StdDevUncertainty` cannot\n",
      "keep track of its correlations by itself, but it can evaluate the correct\n",
      "resulting uncertainty if the correct ``correlation`` is given.\n",
      "\n",
      "The default (``0``) represents uncorrelated while ``1`` means correlated and\n",
      "``-1`` anti-correlated. If given a `numpy.ndarray` it should represent the\n",
      "element-wise correlation coefficient.\n",
      "\n",
      "Examples\n",
      "^^^^^^^^\n",
      "\n",
      "..\n",
      "  EXAMPLE START\n",
      "  Uncertainty with Correlation in NDData\n",
      "\n",
      "Without correlation, subtracting an `~astropy.nddata.NDDataRef` instance from\n",
      "itself results in a non-zero uncertainty::\n",
      "\n",
      "    >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\n",
      "    >>> ndd1.subtract(ndd1, propagate_uncertainties=True).uncertainty  # doctest: +FLOAT_CMP\n",
      "    StdDevUncertainty([14.14213562])\n",
      "\n",
      "Given a correlation of ``1`` (because they clearly correlate) gives the\n",
      "correct uncertainty of ``0``::\n",
      "\n",
      "    >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\n",
      "    >>> ndd1.subtract(ndd1, propagate_uncertainties=True,\n",
      "    ...               uncertainty_correlation=1).uncertainty  # doctest: +FLOAT_CMP\n",
      "    StdDevUncertainty([0.])\n",
      "\n",
      "Which would be consistent with the equivalent operation ``ndd1 * 0``::\n",
      "\n",
      "    >>> ndd1.multiply(0, propagate_uncertainties=True).uncertainty # doctest: +FLOAT_CMP\n",
      "    StdDevUncertainty([0.])\n",
      "\n",
      ".. warning::\n",
      "    The user needs to calculate or know the appropriate value or array manually\n",
      "    and pass it to ``uncertainty_correlation``. The implementation follows\n",
      "    general first order error propagation formulas. See, for example:\n",
      "    `Wikipedia <https://en.wikipedia.org/wiki/Propagation_of_uncertainty#Example_formulas>`_.\n",
      "\n",
      "You can also give element-wise correlations::\n",
      "\n",
      "    >>> ndd1 = NDDataRef([1,1,1,1], uncertainty=StdDevUncertainty([1,1,1,1]))\n",
      "    >>> ndd2 = NDDataRef([2,2,2,2], uncertainty=StdDevUncertainty([2,2,2,2]))\n",
      "    >>> ndd1.add(ndd2,uncertainty_correlation=np.array([1,0.5,0,-1])).uncertainty  # doctest: +FLOAT_CMP\n",
      "    StdDevUncertainty([3.        , 2.64575131, 2.23606798, 1.        ])\n",
      "\n",
      "The correlation ``np.array([1, 0.5, 0, -1])`` would indicate that the first\n",
      "element is fully correlated and the second element partially correlates, while\n",
      "the third element is uncorrelated, and the fourth is anti-correlated.\n",
      "\n",
      "..\n",
      "  EXAMPLE END\n",
      "\n",
      "Uncertainty with Unit\n",
      "---------------------\n",
      "\n",
      "`~astropy.nddata.StdDevUncertainty` implements correct error propagation even\n",
      "if the unit of the data differs from the unit of the uncertainty::\n",
      "\n",
      "    >>> ndd1 = NDDataRef([10], unit='m', uncertainty=StdDevUncertainty([10], unit='cm'))\n",
      "    >>> ndd2 = NDDataRef([20], unit='m', uncertainty=StdDevUncertainty([10]))\n",
      "    >>> ndd1.subtract(ndd2, propagate_uncertainties=True).uncertainty  # doctest: +FLOAT_CMP\n",
      "    StdDevUncertainty([10.00049999])\n",
      "\n",
      "But it needs to be convertible to the unit for the data.\n",
      "\n",
      "\n",
      "  Significant investments to upgrade and construct large-scale scientific\n",
      "facilities demand commensurate investments in R&D to design algorithms and\n",
      "computing approaches to enable scientific and engineering breakthroughs in the\n",
      "big data era. Innovative Artificial Intelligence (AI) applications have powered\n",
      "transformational solutions for big data challenges in industry and technology\n",
      "that now drive a multi-billion dollar industry, and which play an ever\n",
      "increasing role shaping human social patterns. As AI continues to evolve into a\n",
      "computing paradigm endowed with statistical and mathematical rigor, it has\n",
      "become apparent that single-GPU solutions for training, validation, and testing\n",
      "are no longer sufficient for computational grand challenges brought about by\n",
      "scientific facilities that produce data at a rate and volume that outstrip the\n",
      "computing capabilities of available cyberinfrastructure platforms. This\n",
      "realization has been driving the confluence of AI and high performance\n",
      "computing (HPC) to reduce time-to-insight, and to enable a systematic study of\n",
      "domain-inspired AI architectures and optimization schemes to enable data-driven\n",
      "discovery. In this article we present a summary of recent developments in this\n",
      "field, and describe specific advances that authors in this article are\n",
      "spearheading to accelerate and streamline the use of HPC platforms to design\n",
      "and apply accelerated AI algorithms in academia and industry.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## Augmentation & Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Now that we can retrieve the most relevant document based on a question, we can use the retrieved document and send it along with the prompt to increase the context for the LLM.\n",
    "\n",
    "This can also be referred to as the `retrieval-augmented prompt.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2198c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from ssec_tutorials import download_olmo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo = LlamaCpp(\n",
    "    model_path=str(OLMO_MODEL),\n",
    "    temperature=0.8,\n",
    "    verbose=False,\n",
    "    n_ctx=2048,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template using OLMo's tokenizer chat template we saw in module 1.\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=olmo.client.metadata[\"tokenizer.chat_template\"],\n",
    "    template_format=\"jinja2\",\n",
    "    partial_variables={\"add_generation_prompt\": True, \"eos_token\": \"<|endoftext|>\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompt you want to send to OLMo.\n",
    "question = \"What is the best method for multiplying large numbers?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "\n",
    "final_prompt_content = prompt_template.format(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\\\n",
    "                You are an algorithms expert. Please answer the question on algorithms based on the following context:\n",
    "\n",
    "                Context: {context}\n",
    "\n",
    "                Question: {question}\n",
    "            \"\"\",\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bee04b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n",
      "\n",
      "<|user|>\n",
      "                You are an algorithms expert. Please answer the question on algorithms based on the following context:\n",
      "\n",
      "                Context: .. _nddata_arithmetic:\n",
      "\n",
      "NDData Arithmetic\n",
      "*****************\n",
      "\n",
      "Introduction\n",
      "============\n",
      "\n",
      "`~astropy.nddata.NDDataRef` implements the following arithmetic operations:\n",
      "\n",
      "- Addition: :meth:`~astropy.nddata.NDArithmeticMixin.add`\n",
      "- Subtraction: :meth:`~astropy.nddata.NDArithmeticMixin.subtract`\n",
      "- Multiplication: :meth:`~astropy.nddata.NDArithmeticMixin.multiply`\n",
      "- Division: :meth:`~astropy.nddata.NDArithmeticMixin.divide`\n",
      "\n",
      "Using Basic Arithmetic Methods\n",
      "==============================\n",
      "\n",
      "Using the standard arithmetic methods requires that the first operand\n",
      "is an `~astropy.nddata.NDDataRef` instance:\n",
      "\n",
      "    >>> from astropy.nddata import NDDataRef\n",
      "    >>> from astropy.wcs import WCS\n",
      "    >>> import numpy as np\n",
      "    >>> ndd1 = NDDataRef([1, 2, 3, 4])\n",
      "\n",
      "While the requirement for the second operand is that it must be convertible\n",
      "to the first operand. It can be a number::\n",
      "\n",
      "    >>> ndd1.add(3)\n",
      "    NDDataRef([4, 5, 6, 7])\n",
      "\n",
      "Or a `list`::\n",
      "\n",
      "    >>> ndd1.subtract([1,1,1,1])\n",
      "    NDDataRef([0, 1, 2, 3])\n",
      "\n",
      "Or a `numpy.ndarray`::\n",
      "\n",
      "    >>> ndd1.multiply(np.arange(4, 8))\n",
      "    NDDataRef([ 4, 10, 18, 28])\n",
      "    >>> ndd1.divide(np.arange(1,13).reshape(3,4))  # a 3 x 4 numpy array  # doctest: +FLOAT_CMP\n",
      "    NDDataRef([[1.        , 1.        , 1.        , 1.        ],\n",
      "               [0.2       , 0.33333333, 0.42857143, 0.5       ],\n",
      "               [0.11111111, 0.2       , 0.27272727, 0.33333333]])\n",
      "\n",
      "Here, broadcasting takes care of the different dimensions. Several other\n",
      "types of operands are also accepted.\n",
      "\n",
      "Using Arithmetic Classmethods\n",
      "=============================\n",
      "\n",
      "Here both operands do not need to be `~astropy.nddata.NDDataRef`-like::\n",
      "\n",
      "    >>> NDDataRef.add(1, 3)\n",
      "    NDDataRef(4)\n",
      "\n",
      "To wrap the result of an arithmetic operation between two Quantities::\n",
      "\n",
      "    >>> import astropy.units as u\n",
      "    >>> ndd = NDDataRef.multiply([1,2] * u.m, [10, 20] * u.cm)\n",
      "    >>> ndd  # doctest: +FLOAT_CMP\n",
      "    NDDataRef([10., 40.], unit='cm m')\n",
      "    >>> ndd.unit\n",
      "    Unit(\"cm m\")\n",
      "\n",
      "Or take the inverse of an `~astropy.nddata.NDDataRef` object::\n",
      "\n",
      "    >>> NDDataRef.divide(1, ndd1)  # doctest: +FLOAT_CMP\n",
      "    NDDataRef([1.        , 0.5       , 0.33333333, 0.25      ])\n",
      "\n",
      "\n",
      "Possible Operands\n",
      "-----------------\n",
      "\n",
      "The possible types of input for operands are:\n",
      "\n",
      "+ Scalars of any type\n",
      "+ Lists containing numbers (or nested lists)\n",
      "+ ``numpy`` arrays\n",
      "+ ``numpy`` masked arrays\n",
      "+ ``astropy`` quantities\n",
      "+ Other ``nddata`` classes or subclasses\n",
      "\n",
      "Advanced Options\n",
      "================\n",
      "\n",
      "The normal Python operators ``+``, ``-``, etc. are not implemented because\n",
      "the methods provide several options on how to proceed with the additional\n",
      "attributes.\n",
      "\n",
      "Data and Unit\n",
      "-------------\n",
      "\n",
      "For ``data`` and ``unit`` there are no parameters. Every arithmetic\n",
      "operation lets the `astropy.units.Quantity`-framework evaluate the result\n",
      "or fail and abort the operation.\n",
      "\n",
      "Adding two `~astropy.nddata.NDData` objects with the same unit works::\n",
      "\n",
      "    >>> ndd1 = NDDataRef([1,2,3,4,5], unit='m')\n",
      "    >>> ndd2 = NDDataRef([100,150,200,50,500], unit='m')\n",
      "\n",
      "    >>> ndd = ndd1.add(ndd2)\n",
      "    >>> ndd.data  # doctest: +FLOAT_CMP\n",
      "    array([101., 152., 203., 54., 505.])\n",
      "    >>> ndd.unit\n",
      "    Unit(\"m\")\n",
      "\n",
      "Adding two `~astropy.nddata.NDData` objects with compatible units also works::\n",
      "\n",
      "    >>> ndd1 = NDDataRef(ndd1, unit='pc')\n",
      "    INFO: overwriting NDData's current unit with specified unit. [astropy.nddata.nddata]\n",
      "    >>> ndd2 = NDDataRef(ndd2, unit='lyr')\n",
      "    INFO: overwriting NDData's current unit with specified unit. [astropy.nddata.nddata]\n",
      "\n",
      "    >>> ndd = ndd1.subtract(ndd2)\n",
      "    >>> ndd.data  # doctest: +FLOAT_CMP\n",
      "    array([ -29.66013938,  -43.99020907,  -58.32027876,  -11.33006969,\n",
      "           -148.30069689])\n",
      "    >>> ndd.unit\n",
      "    Unit(\"pc\")\n",
      "\n",
      "This will keep by default the unit of the first operand. However, units will\n",
      "not be decomposed during division::\n",
      "\n",
      "    >>> ndd = ndd2.divide(ndd1)\n",
      "    >>> ndd.data  # doctest: +FLOAT_CMP\n",
      "    array([100. , 75. , 66.66666667, 12.5 , 100. ])\n",
      "    >>> ndd.unit\n",
      "    Unit(\"lyr / pc\")\n",
      "\n",
      "Mask\n",
      "----\n",
      "\n",
      "The ``handle_mask`` parameter for the arithmetic operations implements what the\n",
      "resulting mask will be. There are several options.\n",
      "\n",
      "- ``None``, the result will have no ``mask``::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, mask=True)\n",
      "      >>> ndd2 = NDDataRef(1, mask=False)\n",
      "      >>> ndd1.add(ndd2, handle_mask=None).mask is None\n",
      "      True\n",
      "\n",
      "- ``\"first_found\"`` or ``\"ff\"``, the result will have the ``mask`` of the first\n",
      "  operand or if that is ``None``, the ``mask`` of the second operand::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, mask=True)\n",
      "      >>> ndd2 = NDDataRef(1, mask=False)\n",
      "      >>> ndd1.add(ndd2, handle_mask=\"first_found\").mask\n",
      "      True\n",
      "      >>> ndd3 = NDDataRef(1)\n",
      "      >>> ndd3.add(ndd2, handle_mask=\"first_found\").mask\n",
      "      False\n",
      "\n",
      "- A function (or an arbitrary callable) that takes at least two arguments.\n",
      "  For example, `numpy.logical_or` is the default::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, mask=np.array([True, False, True, False]))\n",
      "      >>> ndd2 = NDDataRef(1, mask=np.array([True, False, False, True]))\n",
      "      >>> ndd1.add(ndd2).mask\n",
      "      array([ True, False,  True,  True]...)\n",
      "\n",
      "  This defaults to ``\"first_found\"`` in case only one ``mask`` is not None::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1)\n",
      "      >>> ndd2 = NDDataRef(1, mask=np.array([True, False, False, True]))\n",
      "      >>> ndd1.add(ndd2).mask\n",
      "      array([ True, False, False,  True]...)\n",
      "\n",
      "  Custom functions are also possible::\n",
      "\n",
      "      >>> def take_alternating_values(mask1, mask2, start=0):\n",
      "      ...     result = np.zeros(mask1.shape, dtype=np.bool_)\n",
      "      ...     result[start::2] = mask1[start::2]\n",
      "      ...     result[start+1::2] = mask2[start+1::2]\n",
      "      ...     return result\n",
      "\n",
      "  This function is nonsense, but we can still see how it performs::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, mask=np.array([True, False, True, False]))\n",
      "      >>> ndd2 = NDDataRef(1, mask=np.array([True, False, False, True]))\n",
      "      >>> ndd1.add(ndd2, handle_mask=take_alternating_values).mask\n",
      "      array([ True, False,  True,  True]...)\n",
      "\n",
      "  Additional parameters can be given by prefixing them with ``mask_``\n",
      "  (which will be stripped before passing it to the function)::\n",
      "\n",
      "      >>> ndd1.add(ndd2, handle_mask=take_alternating_values, mask_start=1).mask\n",
      "      array([False, False, False, False]...)\n",
      "      >>> ndd1.add(ndd2, handle_mask=take_alternating_values, mask_start=2).mask\n",
      "      array([False, False,  True,  True]...)\n",
      "\n",
      "Meta\n",
      "----\n",
      "\n",
      "The ``handle_meta`` parameter for the arithmetic operations implements what the\n",
      "resulting ``meta`` will be. The options are the same as for the ``mask``:\n",
      "\n",
      "- If ``None`` the resulting ``meta`` will be an empty `collections.OrderedDict`.\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, meta={'object': 'sun'})\n",
      "      >>> ndd2 = NDDataRef(1, meta={'object': 'moon'})\n",
      "      >>> ndd1.add(ndd2, handle_meta=None).meta\n",
      "      OrderedDict()\n",
      "\n",
      "  For ``meta`` this is the default so you do not need to pass it in this case::\n",
      "\n",
      "      >>> ndd1.add(ndd2).meta\n",
      "      OrderedDict()\n",
      "\n",
      "- If ``\"first_found\"`` or ``\"ff\"``, the resulting ``meta`` will be the ``meta``\n",
      "  of the first operand or if that contains no keys, the ``meta`` of the second\n",
      "  operand is taken.\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, meta={'object': 'sun'})\n",
      "      >>> ndd2 = NDDataRef(1, meta={'object': 'moon'})\n",
      "      >>> ndd1.add(ndd2, handle_meta='ff').meta\n",
      "      {'object': 'sun'}\n",
      "\n",
      "- If it is a ``callable`` it must take at least two arguments. Both ``meta``\n",
      "  attributes will be passed to this function (even if one or both of them are\n",
      "  empty) and the callable evaluates the result's ``meta``. For example, a\n",
      "  function that merges these two::\n",
      "\n",
      "      >>> # It's expected with arithmetic that the result is not a reference,\n",
      "      >>> # so we need to copy\n",
      "      >>> from copy import deepcopy\n",
      "\n",
      "      >>> def combine_meta(meta1, meta2):\n",
      "      ...     if not meta1:\n",
      "      ...         return deepcopy(meta2)\n",
      "      ...     elif not meta2:\n",
      "      ...         return deepcopy(meta1)\n",
      "      ...     else:\n",
      "      ...         meta_final = deepcopy(meta1)\n",
      "      ...         meta_final.update(meta2)\n",
      "      ...         return meta_final\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, meta={'time': 'today'})\n",
      "      >>> ndd2 = NDDataRef(1, meta={'object': 'moon'})\n",
      "      >>> ndd1.subtract(ndd2, handle_meta=combine_meta).meta # doctest: +SKIP\n",
      "      {'object': 'moon', 'time': 'today'}\n",
      "\n",
      "  Here again additional arguments for the function can be passed in using\n",
      "  the prefix ``meta_`` (which will be stripped away before passing it to this\n",
      "  function). See the description for the mask-attribute for further details.\n",
      "\n",
      "World Coordinate System (WCS)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "The ``compare_wcs`` argument will determine what the result's ``wcs`` will be\n",
      "or if the operation should be forbidden. The possible values are identical to\n",
      "``mask`` and ``meta``:\n",
      "\n",
      "- If ``None`` the resulting ``wcs`` will be an empty ``None``.\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, wcs=None)\n",
      "      >>> ndd2 = NDDataRef(1, wcs=WCS())\n",
      "      >>> ndd1.add(ndd2, compare_wcs=None).wcs is None\n",
      "      True\n",
      "\n",
      "- If ``\"first_found\"`` or ``\"ff\"`` the resulting ``wcs`` will be the ``wcs`` of\n",
      "  the first operand or if that is ``None``, the ``meta`` of the second operand\n",
      "  is taken.\n",
      "\n",
      "      >>> wcs = WCS()\n",
      "      >>> ndd1 = NDDataRef(1, wcs=wcs)\n",
      "      >>> ndd2 = NDDataRef(1, wcs=None)\n",
      "      >>> str(ndd1.add(ndd2, compare_wcs='ff').wcs) == str(wcs)\n",
      "      True\n",
      "\n",
      "- If it is a ``callable`` it must take at least two arguments. Both ``wcs``\n",
      "  attributes will be passed to this function (even if one or both of them are\n",
      "  ``None``) and the callable should return ``True`` if these ``wcs`` are\n",
      "  identical (enough) to allow the arithmetic operation or ``False`` if the\n",
      "  arithmetic operation should be aborted with a ``ValueError``. If ``True`` the\n",
      "  ``wcs`` are identical and the first one is used for the result::\n",
      "\n",
      "      >>> def compare_wcs_scalar(wcs1, wcs2, allowed_deviation=0.1):\n",
      "      ...     if wcs1 is None and wcs2 is None:\n",
      "      ...         return True  # both have no WCS so they are identical\n",
      "      ...     if wcs1 is None or wcs2 is None:\n",
      "      ...         return False  # one has WCS, the other doesn't not possible\n",
      "      ...     else:\n",
      "      ...         # Consider wcs close if centers are close enough\n",
      "      ...         return all(abs(wcs1.wcs.crpix - wcs2.wcs.crpix) < allowed_deviation)\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, wcs=None)\n",
      "      >>> ndd2 = NDDataRef(1, wcs=None)\n",
      "      >>> ndd1.subtract(ndd2, compare_wcs=compare_wcs_scalar).wcs\n",
      "\n",
      "\n",
      "  Additional arguments can be passed in prefixing them with ``wcs_`` (this\n",
      "  prefix will be stripped away before passing it to the function)::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, wcs=WCS())\n",
      "      >>> ndd1.wcs.wcs.crpix = [1, 1]\n",
      "      >>> ndd2 = NDDataRef(1, wcs=WCS())\n",
      "      >>> ndd1.subtract(ndd2, compare_wcs=compare_wcs_scalar, wcs_allowed_deviation=2).wcs.wcs.crpix\n",
      "      array([1., 1.])\n",
      "\n",
      "  If you are using `~astropy.wcs.WCS` objects, a very handy function to use\n",
      "  might be::\n",
      "\n",
      "      >>> def wcs_compare(wcs1, wcs2, *args, **kwargs):\n",
      "      ...     return wcs1.wcs.compare(wcs2.wcs, *args, **kwargs)\n",
      "\n",
      "  See :meth:`astropy.wcs.Wcsprm.compare` for the arguments this comparison\n",
      "  allows.\n",
      "\n",
      "Uncertainty\n",
      "-----------\n",
      "\n",
      "The ``propagate_uncertainties`` argument can be used to turn the propagation\n",
      "of uncertainties on or off.\n",
      "\n",
      "- If ``None`` the result will have no uncertainty::\n",
      "\n",
      "      >>> from astropy.nddata import StdDevUncertainty\n",
      "      >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty(0))\n",
      "      >>> ndd2 = NDDataRef(1, uncertainty=StdDevUncertainty(1))\n",
      "      >>> ndd1.add(ndd2, propagate_uncertainties=None).uncertainty is None\n",
      "      True\n",
      "\n",
      "- If ``False`` the result will have the first found uncertainty.\n",
      "\n",
      "  .. note::\n",
      "      Setting ``propagate_uncertainties=False`` is generally not\n",
      "      recommended.\n",
      "\n",
      "- If ``True`` both uncertainties must be ``NDUncertainty`` subclasses that\n",
      "  implement propagation. This is possible for\n",
      "  `~astropy.nddata.StdDevUncertainty`::\n",
      "\n",
      "      >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\n",
      "      >>> ndd2 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\n",
      "      >>> ndd1.add(ndd2, propagate_uncertainties=True).uncertainty  # doctest: +FLOAT_CMP\n",
      "      StdDevUncertainty([14.14213562])\n",
      "\n",
      "Uncertainty with Correlation\n",
      "----------------------------\n",
      "\n",
      "If ``propagate_uncertainties`` is ``True`` you can also give an argument\n",
      "for ``uncertainty_correlation``. `~astropy.nddata.StdDevUncertainty` cannot\n",
      "keep track of its correlations by itself, but it can evaluate the correct\n",
      "resulting uncertainty if the correct ``correlation`` is given.\n",
      "\n",
      "The default (``0``) represents uncorrelated while ``1`` means correlated and\n",
      "``-1`` anti-correlated. If given a `numpy.ndarray` it should represent the\n",
      "element-wise correlation coefficient.\n",
      "\n",
      "Examples\n",
      "^^^^^^^^\n",
      "\n",
      "..\n",
      "  EXAMPLE START\n",
      "  Uncertainty with Correlation in NDData\n",
      "\n",
      "Without correlation, subtracting an `~astropy.nddata.NDDataRef` instance from\n",
      "itself results in a non-zero uncertainty::\n",
      "\n",
      "    >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\n",
      "    >>> ndd1.subtract(ndd1, propagate_uncertainties=True).uncertainty  # doctest: +FLOAT_CMP\n",
      "    StdDevUncertainty([14.14213562])\n",
      "\n",
      "Given a correlation of ``1`` (because they clearly correlate) gives the\n",
      "correct uncertainty of ``0``::\n",
      "\n",
      "    >>> ndd1 = NDDataRef(1, uncertainty=StdDevUncertainty([10]))\n",
      "    >>> ndd1.subtract(ndd1, propagate_uncertainties=True,\n",
      "    ...               uncertainty_correlation=1).uncertainty  # doctest: +FLOAT_CMP\n",
      "    StdDevUncertainty([0.])\n",
      "\n",
      "Which would be consistent with the equivalent operation ``ndd1 * 0``::\n",
      "\n",
      "    >>> ndd1.multiply(0, propagate_uncertainties=True).uncertainty # doctest: +FLOAT_CMP\n",
      "    StdDevUncertainty([0.])\n",
      "\n",
      ".. warning::\n",
      "    The user needs to calculate or know the appropriate value or array manually\n",
      "    and pass it to ``uncertainty_correlation``. The implementation follows\n",
      "    general first order error propagation formulas. See, for example:\n",
      "    `Wikipedia <https://en.wikipedia.org/wiki/Propagation_of_uncertainty#Example_formulas>`_.\n",
      "\n",
      "You can also give element-wise correlations::\n",
      "\n",
      "    >>> ndd1 = NDDataRef([1,1,1,1], uncertainty=StdDevUncertainty([1,1,1,1]))\n",
      "    >>> ndd2 = NDDataRef([2,2,2,2], uncertainty=StdDevUncertainty([2,2,2,2]))\n",
      "    >>> ndd1.add(ndd2,uncertainty_correlation=np.array([1,0.5,0,-1])).uncertainty  # doctest: +FLOAT_CMP\n",
      "    StdDevUncertainty([3.        , 2.64575131, 2.23606798, 1.        ])\n",
      "\n",
      "The correlation ``np.array([1, 0.5, 0, -1])`` would indicate that the first\n",
      "element is fully correlated and the second element partially correlates, while\n",
      "the third element is uncorrelated, and the fourth is anti-correlated.\n",
      "\n",
      "..\n",
      "  EXAMPLE END\n",
      "\n",
      "Uncertainty with Unit\n",
      "---------------------\n",
      "\n",
      "`~astropy.nddata.StdDevUncertainty` implements correct error propagation even\n",
      "if the unit of the data differs from the unit of the uncertainty::\n",
      "\n",
      "    >>> ndd1 = NDDataRef([10], unit='m', uncertainty=StdDevUncertainty([10], unit='cm'))\n",
      "    >>> ndd2 = NDDataRef([20], unit='m', uncertainty=StdDevUncertainty([10]))\n",
      "    >>> ndd1.subtract(ndd2, propagate_uncertainties=True).uncertainty  # doctest: +FLOAT_CMP\n",
      "    StdDevUncertainty([10.00049999])\n",
      "\n",
      "But it needs to be convertible to the unit for the data.\n",
      "\n",
      "\n",
      "  Significant investments to upgrade and construct large-scale scientific\n",
      "facilities demand commensurate investments in R&D to design algorithms and\n",
      "computing approaches to enable scientific and engineering breakthroughs in the\n",
      "big data era. Innovative Artificial Intelligence (AI) applications have powered\n",
      "transformational solutions for big data challenges in industry and technology\n",
      "that now drive a multi-billion dollar industry, and which play an ever\n",
      "increasing role shaping human social patterns. As AI continues to evolve into a\n",
      "computing paradigm endowed with statistical and mathematical rigor, it has\n",
      "become apparent that single-GPU solutions for training, validation, and testing\n",
      "are no longer sufficient for computational grand challenges brought about by\n",
      "scientific facilities that produce data at a rate and volume that outstrip the\n",
      "computing capabilities of available cyberinfrastructure platforms. This\n",
      "realization has been driving the confluence of AI and high performance\n",
      "computing (HPC) to reduce time-to-insight, and to enable a systematic study of\n",
      "domain-inspired AI architectures and optimization schemes to enable data-driven\n",
      "discovery. In this article we present a summary of recent developments in this\n",
      "field, and describe specific advances that authors in this article are\n",
      "spearheading to accelerate and streamline the use of HPC platforms to design\n",
      "and apply accelerated AI algorithms in academia and industry.\n",
      "\n",
      "\n",
      "                Question: What is the best method for multiplying large numbers?\n",
      "            \n",
      "\n",
      "\n",
      "<|assistant|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_prompt_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073742e1",
   "metadata": {},
   "source": [
    "You can see above that we now have a `context` input within the prompt.\n",
    "This context is the content of the document(s) that we retrieved from the Qdrant database.\n",
    "With this context, the LLM can generate more relevant responses.\n",
    "So let's see how it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c23cfea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26449257",
   "metadata": {},
   "source": [
    "### OLMo with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5030cd5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Requested tokens (5234) exceed context window of 2048",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43molmo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_prompt_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mStreamingStdOutCallbackHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:276\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    288\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:1322\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1321\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1322\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_community/llms/llamacpp.py:288\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     combined_text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 288\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombined_text_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_community/llms/llamacpp.py:341\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameters(stop), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    340\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(prompt\u001b[38;5;241m=\u001b[39mprompt, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 341\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/llama_cpp/llama.py:1062\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx\u001b[38;5;241m.\u001b[39mreset_timings()\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prompt_tokens) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_ctx:\n\u001b[0;32m-> 1062\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1063\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested tokens (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prompt_tokens)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exceed context window of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllama_cpp\u001b[38;5;241m.\u001b[39mllama_n_ctx(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1064\u001b[0m     )\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_tokens \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;66;03m# Unlimited, depending on n_ctx.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m     max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_ctx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompt_tokens)\n",
      "\u001b[0;31mValueError\u001b[0m: Requested tokens (5234) exceed context window of 2048"
     ]
    }
   ],
   "source": [
    "olmo.invoke(\n",
    "    final_prompt_content, config={\"callbacks\": [StreamingStdOutCallbackHandler()]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb26355",
   "metadata": {},
   "source": [
    "### OLMo without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "422daa7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43molmo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mStreamingStdOutCallbackHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:276\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    288\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:1322\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1321\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1322\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_community/llms/llamacpp.py:288\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     combined_text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 288\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombined_text_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_community/llms/llamacpp.py:341\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameters(stop), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    340\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(prompt\u001b[38;5;241m=\u001b[39mprompt, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 341\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/llama_cpp/llama.py:1109\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1107\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1108\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1109\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_token_is_eog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/llama_cpp/llama.py:731\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 731\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    733\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    734\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    735\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    749\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    750\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/llama_cpp/llama.py:569\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    565\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    567\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    568\u001b[0m )\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/llama_cpp/_internals.py:325\u001b[0m, in \u001b[0;36m_LlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 325\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "olmo.invoke(question, config={\"callbacks\": [StreamingStdOutCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a35bf4",
   "metadata": {},
   "source": [
    "From the responses above, we can see that the response with context is more relevant and informative compared to the response without context, an this shows the power of the RAG framework, with just a few documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "One way to generate the response with OLMo is to build `context` using the `question` beforehand, as shown above, create an llm_chain then `invoke` it with `messages`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "However, We can further use [LangChain's convenience functions](https://python.langchain.com/v0.2/docs/tutorials/rag/#built-in-chains) to streamline our pipeline using [create_stuff_documents_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html) and [create_retrieval_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html) from the main `langchain` package.\n",
    "\n",
    "The main `langchain` package contains chains, agents, and retrieval strategies that make up an application's cognitive architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "`create_stuff_documents_chain` specifies how retrieved context is fed into a prompt and LLM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "On looking its signature, notice that it accepts `prompt` argument of type `BasePromptTemplate` but it needs input keys as `context` and `input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "205799a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e663f",
   "metadata": {},
   "source": [
    "To use the helper functions,\n",
    "we'll need to setup our template string to use the `context` and `input` keys as variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'input'], template='<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context.\\nContext: {context}\\nQuestion: {input}\\n\\n\\n\\n<|assistant|>\\n\\n')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new prompt_template\n",
    "# so that it accepts `context` and `input` as input_variables\n",
    "input_string_template = \"\"\"\\\n",
    "You are an astrophysics expert. Please answer the question on astrophysics based on the following context.\n",
    "Context: {context}\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "transformed_prompt_template = PromptTemplate.from_template(\n",
    "    prompt_template.partial(\n",
    "        messages=[{\"role\": \"user\", \"content\": input_string_template}]\n",
    "    ).format()\n",
    ")\n",
    "transformed_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=olmo, prompt=transformed_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "We can run this by passing in the context directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is dark matter?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdocument_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mStreamingStdOutCallbackHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/runnables/base.py:4588\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   4583\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4584\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4585\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4586\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4587\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 4588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4589\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4590\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4592\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/runnables/base.py:2507\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2506\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2507\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2508\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:276\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    288\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_core/language_models/llms.py:1322\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1321\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1322\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_community/llms/llamacpp.py:288\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     combined_text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 288\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombined_text_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/langchain_community/llms/llamacpp.py:341\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameters(stop), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    340\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(prompt\u001b[38;5;241m=\u001b[39mprompt, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 341\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpart\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/llama_cpp/llama.py:1109\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1107\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1108\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1109\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_token_is_eog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/llama_cpp/llama.py:731\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 731\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    733\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    734\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    735\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    749\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    750\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/llama_cpp/llama.py:569\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    565\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    567\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    568\u001b[0m )\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m~/miniconda3/envs/ssec-scipy2024/lib/python3.11/site-packages/llama_cpp/_internals.py:325\u001b[0m, in \u001b[0;36m_LlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 325\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question = \"What is dark matter?\"\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"input\": question,\n",
    "        \"context\": retriever.invoke(question),\n",
    "    },\n",
    "    config={\"callbacks\": [StreamingStdOutCallbackHandler()]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "However, we want the context to be dynamically generated using the passed input or question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "From LangChain's documentation: `create_retrieval_chain` adds the retrieval step and propagates the retrieved context through the chain, providing it alongside the final answer. It has input key `input`, and includes input, context, and answer in its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark matter is a theoretical entity that is still not directly observed or detected in our universe, despite its significant presence based on gravitational arguments and astronomical observations. According to astrophysics, approximately 90% of the visible mass in the Universe is believed to be non-luminous dark matter, which does not emit, reflect, or absorb light. Dark matter particles are yet to be discovered, but they have been predicted by particle physics based on supersymmetry (SUSY). SUSY predicts that dark matter can take various forms such as the neutralino, a particle that is an inert supersymmetric partner of the known photon and lepton particles.\n",
      "\n",
      "The term \"dark\" refers to its inability to be detected or observed using electromagnetic radiation, making it difficult to study directly. Dark matter could exist in various forms like compact dark objects (CDOs) - hypothetical particles with no interaction with normal matter, moving freely inside Earth, and producing a time-dependent signal in a gravimeter due to their low mass and orbital radius.\n",
      "\n",
      "Despite numerous experiments searching for evidence of dark matter, it remains an enigmatic scientific mystery. However, recent observations claim the first direct evidence of dark matter, which highlights the ongoing efforts to uncover this mysterious substance."
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke(\n",
    "    {\"input\": \"What is dark matter?\"},\n",
    "    config={\"callbacks\": [StreamingStdOutCallbackHandler()]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is dark matter?',\n",
       " 'context': [Document(page_content='  One of the great scientific enigmas still unsolved, the existence of dark\\nmatter, is reviewed. Simple gravitational arguments imply that most of the mass\\nin the Universe, at least 90%, is some (unknown) non-luminous matter. Some\\nparticle candidates for dark matter are discussed with particular emphasis on\\nthe neutralino, a particle predicted by the supersymmetric extension of the\\nStandard Model of particle physics. Experiments searching for these relic\\nparticles, carried out by many groups around the world, are also discussed.\\nThese experiments are becoming more sensitive every year and in fact one of the\\ncollaborations claims that the first direct evidence for dark matter has\\nalready been observed.\\n', metadata={'id': 'hep-ph/0110122', 'title': 'The Enigma of the Dark Matter', '_id': '4ab99f7c922747d9a6a34b855d959779', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       "  Document(page_content='  Dark matter could be composed of compact dark objects (CDOs). These objects\\nmay interact very weakly with normal matter and could move freely {\\\\it inside}\\nthe Earth. A CDO moving in the inner core of the Earth will have an orbital\\nperiod near 55 min and produce a time dependent signal in a gravimeter. Data\\nfrom superconducting gravimeters rule out such objects moving inside the Earth\\nunless their mass $m_D$ and or orbital radius $a$ are very small so that $m_D\\\\,\\na < 1.2\\\\times 10^{-13}M_\\\\oplus R_\\\\oplus$. Here $M_\\\\oplus$ and $R_\\\\oplus$ are\\nthe mass and radius of the Earth.\\n', metadata={'id': 1912.0094, 'title': 'Gravimeter search for compact dark matter objects moving in the Earth', '_id': '97fa0dcbd2aa45d28dfccaa150e724e2', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})],\n",
       " 'answer': 'Dark matter is a theoretical entity that is still not directly observed or detected in our universe, despite its significant presence based on gravitational arguments and astronomical observations. According to astrophysics, approximately 90% of the visible mass in the Universe is believed to be non-luminous dark matter, which does not emit, reflect, or absorb light. Dark matter particles are yet to be discovered, but they have been predicted by particle physics based on supersymmetry (SUSY). SUSY predicts that dark matter can take various forms such as the neutralino, a particle that is an inert supersymmetric partner of the known photon and lepton particles.\\n\\nThe term \"dark\" refers to its inability to be detected or observed using electromagnetic radiation, making it difficult to study directly. Dark matter could exist in various forms like compact dark objects (CDOs) - hypothetical particles with no interaction with normal matter, moving freely inside Earth, and producing a time-dependent signal in a gravimeter due to their low mass and orbital radius.\\n\\nDespite numerous experiments searching for evidence of dark matter, it remains an enigmatic scientific mystery. However, recent observations claim the first direct evidence of dark matter, which highlights the ongoing efforts to uncover this mysterious substance.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b91fe4",
   "metadata": {},
   "source": [
    "One of the nice things about the LangChain helper function is that the result is a dictionary containing the `input`, `context`, and `answer` keys, so you can easily see what you asked and the context that was used to generate the answer.\n",
    "\n",
    "This way of creating the RAG pipeline is quick, but not as customizable. If you need more control over the input variables, we'll need to create our own chain.\n",
    "\n",
    "In the next module, we'll explore how to do this to create a simple Panel application that uses the RAG pipeline to generate responses to user questions.\n",
    "\n",
    "For now let's clean up the qdrant client by closing it before the next module, otherwise we'll run into errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a9d42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant.client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssec-scipy2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
